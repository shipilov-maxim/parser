### Что было сделано

Был написан скрипт на Python с использованием библиотек `requests` и `BeautifulSoup` для парсинга данных с
сайта https://quotes.toscrape.com/. Скрипт извлекает цитаты, авторов и теги, связанные с каждой цитатой, и сохраняет
результаты в формате JSON.

### Откуда были получены данные

Данные были получены с веб-сайта https://quotes.toscrape.com/. Это учебный сайт, специально созданный для практики
веб-скрейпинга.

### Как осуществлялся сбор

1. **Импорт библиотек**: Для начала были импортированы необходимые библиотеки:
    - `requests` для отправки HTTP-запросов к веб-страницам.
    - `BeautifulSoup` из пакета `bs4` для парсинга HTML-кода.
    - `json` для сохранения данных в формате JSON.

2. **Отправка HTTP-запроса**: С помощью `requests.get` был отправлен запрос к главной странице сайта и получен HTML-код.

3. **Парсинг страницы**: С помощью `BeautifulSoup` был разобран HTML-код, и выбраны необходимые элементы (цитаты, авторы
   и теги).

4. **Сбор данных**: Собранные данные были сохранены в виде списка словарей.

5. **Сохранение данных в файл**: С помощью `json.dump` результаты были записаны в файл `data.json`.

### Почему был выбран тот или иной метод/инструмент, а не другой

- **requests** — удобная библиотека для выполнения HTTP-запросов.
- **BeautifulSoup** — мощный инструмент для парсинга HTML, обеспечивающий интуитивно понятный синтаксис для навигации по
  дереву HTML-документа.